The tokenizer is a simple lexer that splits text into tokens. (See [Tokens](GalacticTokens.java))